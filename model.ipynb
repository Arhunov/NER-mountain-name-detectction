{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87554a6d-a908-4931-9fea-ac939ce31f03",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4eefc6a8-efa4-4032-a107-13fa97f77269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformers does not support keras 3, so using keras 2\n",
    "import os\n",
    "os.environ['TF_USE_LEGACY_KERAS'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f853789-3679-4bf4-8a3f-20578cd4d239",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, TFAutoModelForTokenClassification, pipeline\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5c174e-80e4-4273-a76d-ecee979c7b18",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e890a0a-408e-4dd1-9d66-d66d08b732d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read dataset\n",
    "with open('mountain_ner_data.pkl', 'rb') as file:\n",
    "    data = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c23dcad9-aff1-4f02-a8e9-9227458e018f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"Hey, did you know that [Chokai] is actually a volcano? It's so cool! I've always wanted to visit [Tsukuba], maybe we should plan a trip? My friend went hiking in [the Andes] last year and said it was incredible. Have you ever seen a photo of [Hood]? It looks so dangerous. Oh, and I read that the Nile River is the longest in the world.\\n\",\n",
       " 'text_format': 'whatsup conversation',\n",
       " 'text_theme': 'mountains',\n",
       " 'text_size': 'small',\n",
       " 'is_lower': False}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chek first record\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ff26bd9-bb02-432b-821e-eff940532034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer for the base model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1b6fd2d6-5977-4ae3-8eb5-d5b01085cfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens_to_labels(tokens, b_label_id = 1, i_label_id = 2):\n",
    "    \"\"\"\n",
    "    Converts a sequence of tokens into label IDs based on the B-I-O (Begin-Inside-Outside) labeling scheme.\n",
    "    \n",
    "    Args:\n",
    "        tokens (list of str): A list of tokens (e.g., words or subwords) to be labeled.\n",
    "        b_label_id (int, optional): Label ID for the beginning of a named entity (default: 1).\n",
    "        i_label_id (int, optional): Label ID for the inside of a named entity (default: 2).\n",
    "\n",
    "    Returns:\n",
    "        np.array: An array of label IDs corresponding to the input tokens.\n",
    "    \"\"\"\n",
    "    \n",
    "    labels = np.array([0]) # adding label for SOS token\n",
    "    name_going = False\n",
    "    \n",
    "    # Searching for [ or ] in tokens.\n",
    "    # The tokenizer vocabulary does not contain any non-special tokens that include [ or ] along with other symbols.\n",
    "    for token in tokens:\n",
    "        # if token contains close bracket, target entity is ended\n",
    "        if token.endswith(']'):\n",
    "            name_going = False\n",
    "        # if name_going is True, token is part of the target entity\n",
    "        elif name_going:\n",
    "            if first_tok: # begin of the target entity\n",
    "                labels = np.append(labels, b_label_id) # adding begin label\n",
    "                first_tok = False\n",
    "            else: # inside of the target entity\n",
    "                labels = np.append(labels, i_label_id) # adding inside label\n",
    "        # if token contains open bracket, target entity is started\n",
    "        elif token.startswith('['):\n",
    "            first_tok = True\n",
    "            name_going = True\n",
    "        # else add zero label\n",
    "        else:\n",
    "            labels = np.append(labels, 0)\n",
    "            \n",
    "    # Adding label for EOS token\n",
    "    labels = np.append(labels, 0)\n",
    "    return labels\n",
    "\n",
    "def text_to_labels(text, seq_len = 512):\n",
    "    \"\"\"\n",
    "    Process text to tokens and labels\n",
    "\n",
    "    Args:\n",
    "    text (str): text for processing\n",
    "    max_len (int): max lenght of the sequence, rest will be padded.\n",
    "\n",
    "    Returns:\n",
    "    Tokenizer object {'input_ids': np.array([]), 'attention_mask': np.array([]), 'token_type_ids': np.array([])},\n",
    "    Numpy array of labels\n",
    "    \"\"\"\n",
    "    # Recieve labels from the text\n",
    "    str_tokens = tokenizer.tokenize(text)\n",
    "    labels = tokens_to_labels(str_tokens)\n",
    "\n",
    "    # Delete brackets from the text\n",
    "    text = text.replace(\"[\", \"\").replace(\"]\", \"\")\n",
    "    \n",
    "    # Chek if len labels match len tokens\n",
    "    token_obj = tokenizer(text, return_attention_mask = True, return_tensors=\"np\")\n",
    "    if len(labels) != len(token_obj['input_ids'][0]):\n",
    "        print(f\"Lens don`t match. label len = {len(labels)} and token len = {len(token_obj['input_ids'][0])}\")\n",
    "        raise ValueError\n",
    "\n",
    "    # padding \n",
    "    labels_padded = np.zeros(seq_len, dtype = np.int32)\n",
    "    pad_id = seq_len if len(labels) > seq_len else len(labels)\n",
    "    labels_padded[:pad_id] = labels[:pad_id]\n",
    "    token_obj_padded = tokenizer(text, return_attention_mask = True, return_tensors=\"np\", padding = 'max_length', max_length=512, truncation=True)\n",
    "    \n",
    "    return token_obj_padded, labels_padded\n",
    "\n",
    "def create_tf_dataset(input_ids, attention_mask, token_type_ids, labels, batch_size):\n",
    "    \"\"\"\n",
    "    Returns tensorflow dataset from data\n",
    "    \"\"\"\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((\n",
    "        {'input_ids': input_ids, \n",
    "         'attention_mask': attention_mask,\n",
    "         'token_type_ids': token_type_ids}, \n",
    "        labels))\n",
    "    \n",
    "    dataset = dataset.batch(batch_size) # set batch size\n",
    "    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE) # preload part of the data to speed up training\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def data_process(data, batch_size = 1, seq_len = 512, test_part = 0.15):\n",
    "    \"\"\"\n",
    "    Processing data to tensorflow dataset\n",
    "\n",
    "    Args:\n",
    "    data (list): list of dictionaries, that have the 'text' column\n",
    "    batch_size (int): batch size\n",
    "    seq_len (int): len of the target sequence\n",
    "    test_part (float): part of the data for test dataset\n",
    "\n",
    "    Returns:\n",
    "    train_dataset,\n",
    "    test_dataset\n",
    "    \"\"\"\n",
    "    data_len = len(data)\n",
    "    train_len = int(data_len * (1-test_part))\n",
    "\n",
    "    # initial arrays to save features\n",
    "    input_ids_array = np.zeros((data_len, seq_len), dtype = np.int32)\n",
    "    attention_mask_array = np.zeros((data_len, seq_len), dtype = np.int32)\n",
    "    token_type_ids_array = np.zeros((data_len, seq_len), dtype = np.int32)\n",
    "    labels_array = np.zeros((data_len, seq_len), dtype = np.int32)\n",
    "\n",
    "    # iterate for every entry in data\n",
    "    for i, entry in enumerate(data):\n",
    "        # recieve features from data\n",
    "        tokens, labels = text_to_labels(entry['text'])\n",
    "        # record features\n",
    "        input_ids_array[i] = tokens['input_ids']\n",
    "        attention_mask_array[i] = tokens['attention_mask']\n",
    "        token_type_ids_array[i] = tokens['token_type_ids']\n",
    "        labels_array[i] = labels\n",
    "        \n",
    "    # creating datasets\n",
    "    train_ds = create_tf_dataset(input_ids_array[:train_len],\n",
    "                                 attention_mask_array[:train_len],\n",
    "                                 token_type_ids_array[:train_len],\n",
    "                                 labels_array[:train_len],\n",
    "                                 batch_size)\n",
    "    \n",
    "    test_ds = create_tf_dataset(input_ids_array[train_len:],\n",
    "                                attention_mask_array[train_len:],\n",
    "                                token_type_ids_array[train_len:],\n",
    "                                labels_array[train_len:],\n",
    "                                batch_size)\n",
    "    \n",
    "    return train_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "adb6e60c-6f4d-4913-8570-f961e7cf90b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_ds, test_ds = data_process(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e608e346-42a0-47ce-b305-dd45b6b7e7fe",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d305940c-4629-437b-9ed3-73dc9c4f3ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForTokenClassification.\n",
      "\n",
      "All the weights of TFBertForTokenClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForTokenClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Load model from pretraining\n",
    "# Original paper: https://huggingface.co/dslim/bert-base-NER\n",
    "model = TFAutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\")\n",
    "# Change last layer\n",
    "model.classifier = tf.keras.layers.Dense(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aabd2218-6369-4bf5-9fb8-aad9291e9820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling model\n",
    "model.compile(optimizer=Adam(3e-5), metrics = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be16dbc4-f12d-4b62-bbc5-1475b3468442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "WARNING:tensorflow:AutoGraph could not transform <function infer_framework at 0x7f91fab1b920> and will run it as-is.\n",
      "Cause: for/else statement not yet supported\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function infer_framework at 0x7f91fab1b920> and will run it as-is.\n",
      "Cause: for/else statement not yet supported\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1736273300.792010     858 service.cc:145] XLA service 0x7f90784acdd0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1736273300.792064     858 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce GTX 1080, Compute Capability 6.1\n",
      "2025-01-07 18:08:20.863387: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-01-07 18:08:21.111765: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8906\n",
      "I0000 00:00:1736273301.304152     858 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "253/253 [==============================] - 118s 234ms/step - loss: 0.0457 - accuracy: 0.9840 - val_loss: 0.0103 - val_accuracy: 0.9970\n",
      "Epoch 2/2\n",
      "253/253 [==============================] - 51s 201ms/step - loss: 0.0104 - accuracy: 0.9966 - val_loss: 0.0096 - val_accuracy: 0.9971\n"
     ]
    }
   ],
   "source": [
    "# Fiting model\n",
    "history = model.fit(train_ds, validation_data=test_ds, epochs = 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92c5244e-fe0b-4644-b9ab-3714e3cb4473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(None, 3), dtype=tf.float32, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f906f145090>, 140260622580768), {}).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(None, 3), dtype=tf.float32, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f906f145090>, 140260622580768), {}).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(3,), dtype=tf.float32, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f906f001690>, 140259541139616), {}).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(3,), dtype=tf.float32, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f906f001690>, 140259541139616), {}).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(None, 3), dtype=tf.float32, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f906f145090>, 140260622580768), {}).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(None, 3), dtype=tf.float32, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f906f145090>, 140260622580768), {}).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(3,), dtype=tf.float32, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f906f001690>, 140259541139616), {}).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(3,), dtype=tf.float32, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f906f001690>, 140259541139616), {}).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: mount_ner_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: mount_ner_model/assets\n"
     ]
    }
   ],
   "source": [
    "# Saving model\n",
    "model.save('mount_ner_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6706fa57-02f2-48b2-82ae-5bb5bbd2ad75",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ed09bb9a-b2b7-48b2-a2f3-5aa8fe9e22f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_spans(labels, tokens):\n",
    "    \"\"\"\n",
    "    Extract spans of labeled tokens.\n",
    "\n",
    "    Args:\n",
    "        labels: List of labels for each token.\n",
    "        tokens: List of tokens.\n",
    "\n",
    "    Returns:\n",
    "        list: List of (start_index, end_index) tuples representing spans.\n",
    "    \"\"\"\n",
    "    spans = []\n",
    "    current_span_start = None\n",
    "    for i, label in enumerate(labels):\n",
    "        if label == 1:  # Start of a span\n",
    "            if current_span_start is None:\n",
    "                current_span_start = len(\"\".join(tokens[:i]).replace(\" ##\", \"\"))\n",
    "        elif label != 2 and current_span_start is not None:  # End of a span (not a continuation and a span started)\n",
    "            spans.append((current_span_start, len(\"\".join(tokens[:i]).replace(\" ##\", \"\"))))\n",
    "            current_span_start = None\n",
    "    if current_span_start is not None: # Handle spans ending at the end of the sequence\n",
    "        spans.append((current_span_start, len(\"\".join(tokens).replace(\" ##\", \"\"))))\n",
    "    return spans\n",
    "\n",
    "def get_char_index(tokens, token_index):\n",
    "    \"\"\"\n",
    "    Calculate the character index of a token.\n",
    "\n",
    "    Args:\n",
    "        tokens: List of tokens.\n",
    "        token_index: Index of the token.\n",
    "\n",
    "    Returns:\n",
    "        int: Character index.\n",
    "    \"\"\"\n",
    "    return len(\"\".join(tokens[:token_index]).replace(\" ##\", \"\"))\n",
    "\n",
    "def evaluate(model, tokenizer, sample):\n",
    "    \"\"\"\n",
    "    Evaluate model by 1 entry from test data\n",
    "\n",
    "    Args:\n",
    "        model: tuned model\n",
    "        sample: entry from data\n",
    "        tokenizer: model tokenizer\n",
    "\n",
    "    Returns:\n",
    "        list: list of predicted selections.\n",
    "    \"\"\"\n",
    "    # Get model predictions and probabilities\n",
    "    pred = model.predict(sample[0])\n",
    "    logits = pred.logits\n",
    "    softmax = tf.nn.softmax(logits, axis=-1)\n",
    "    predicted_classes = np.argmax(softmax, axis=-1)[0]\n",
    "    true_classes = sample[1].numpy()[0]\n",
    "    \n",
    "    # Convert token IDs to tokens and remove special tokens\n",
    "    tokens = tokenizer.convert_ids_to_tokens(sample[0]['input_ids'][0])\n",
    "    tokens_without_special = [token for token in tokens if token not in [\"[CLS]\", \"[SEP]\", \"[PAD]\"]]\n",
    "\n",
    "    # Extract predicted and true spans\n",
    "    predicted_spans = extract_spans(predicted_classes[1:], tokens_without_special)\n",
    "    true_spans = extract_spans(true_classes[1:], tokens_without_special)\n",
    "    \n",
    "    # Prepare colored text for visualization\n",
    "    colored_text = \"\"\n",
    "    processed_text = \"\"\n",
    "    last_index = 0\n",
    "    \n",
    "    # Iterate through tokens and apply coloring based on predictions and ground truth\n",
    "    for i, token in enumerate(tokens_without_special):\n",
    "        start_index = get_char_index(tokens_without_special, i)\n",
    "        end_index = get_char_index(tokens_without_special, i + 1)\n",
    "\n",
    "        is_predicted = False\n",
    "        for p_start, p_end in predicted_spans:\n",
    "            if p_start <= start_index < p_end:\n",
    "                is_predicted = True\n",
    "                break\n",
    "\n",
    "        is_true = False\n",
    "        for t_start, t_end in true_spans:\n",
    "            if t_start <= start_index < t_end:\n",
    "                is_true = True\n",
    "                break\n",
    "\n",
    "        token_text = token.replace(\"##\", \"\")\n",
    "        \n",
    "        # Apply different colors based on prediction and truth values\n",
    "        if is_predicted and is_true:\n",
    "            color = \"green\"\n",
    "            colored_text += f\"<span style='color: {color};'>{token_text}</span>\"\n",
    "        elif is_predicted and not is_true:\n",
    "            color = \"red\"\n",
    "            colored_text += f\"<span style='color: {color};'>{token_text}</span>\"\n",
    "        elif not is_predicted and is_true:\n",
    "            color = \"yellow\"\n",
    "            colored_text += f\"<span style='color: {color};'>{token_text}</span>\"\n",
    "        else:\n",
    "            colored_text += token_text\n",
    "            \n",
    "        # Add space between tokens unless the next token is a subword\n",
    "        if i < len(tokens_without_special) - 1 and not (tokens_without_special[i+1].startswith(('##', '.', ',', '\"', '\\''))):\n",
    "            colored_text += \" \"\n",
    "\n",
    "    display(HTML(colored_text))\n",
    "    print(predicted_spans)\n",
    "    return predicted_spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "02cf35e4-68eb-4558-b4f7-c3a747e61627",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = iter(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5166bb40-6dba-496c-8259-c5ffda9d817f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Green if correct, red if incorect true, yellow if incorect false\n",
      "1/1 [==============================] - 0s 98ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Hey, did you know the Nile flows into the Mediterranean Sea ? It' s so long ! And I was reading about the <span style='color: green;'>Andes</span>, they are massive. The Amazon is another huge river, flowing through Brazil. It' s crazy to think how many rivers start in <span style='color: green;'>Fi</span><span style='color: green;'>tz</span> <span style='color: green;'>Roy</span>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(83, 88), (189, 198)]\n",
      "1/1 [==============================] - 0s 92ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "the small village of kumbu sits in the shadow of <span style='color: green;'>mount</span> <span style='color: green;'>ever</span><span style='color: green;'>est</span>. the nearby city of kathmandu is a bustling hub for travelers heading to the <span style='color: yellow;'>him</span><span style='color: yellow;'>alaya</span><span style='color: yellow;'>s</span>. many adventurers start their climb from this point to experience the great beauty of <span style='color: green;'>an</span><span style='color: green;'>nap</span><span style='color: green;'>urn</span><span style='color: green;'>a</span>. another popular area for climbers is the <span style='color: green;'>al</span><span style='color: green;'>ps</span>, with cities like chamonix offering great views of <span style='color: green;'>mon</span><span style='color: green;'>t</span> <span style='color: green;'>b</span><span style='color: green;'>lan</span><span style='color: green;'>c</span>. in south america, you can find the <span style='color: green;'>z</span><span style='color: green;'>ao</span> mountain range, which is near santiago."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(43, 57), (215, 230), (267, 273), (320, 335), (368, 373)]\n",
      "1/1 [==============================] - 0s 94ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Okay, let' s begin. Welcome back to\" Nature' s Narratives,\" I' m your host, David. Today, we' re exploring the breathtaking landscapes of Yellowstone National Park. This park, situated mainly in Wyoming, includes parts of Montana and Idaho, and is famous for its geothermal features like <span style='color: red;'>Old</span> Faithful geyser and the Grand Prismatic Spring. <span style='color: green;'>Te</span><span style='color: green;'>ton</span> <span style='color: green;'>Range</span>, visible to the south of the park, also plays a very significant role in its ecosystem. The Snake River winds its way through the park and feeds into various smaller lakes within its boundaries. Many visitors hike up to the top of various peaks on <span style='color: green;'>A</span><span style='color: green;'>bs</span><span style='color: green;'>aro</span><span style='color: green;'>ka</span> <span style='color: green;'>Range</span> for stunning views of the entire area. The park' s beauty is truly unparalleled."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(254, 257), (308, 320), (523, 542)]\n",
      "1/1 [==============================] - 0s 99ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "hey ! did you know that people living near the <span style='color: green;'>and</span><span style='color: green;'>es</span> have a rich history of terraced farming ? it' s amazing how they' ve adapted. yeah, and their music often reflects the sounds of the <span style='color: green;'>hi</span><span style='color: green;'>uchi</span><span style='color: green;'>gata</span><span style='color: green;'>ke</span>, with instruments like the charango. also, i' ve heard their mythology is full of stories about the spirits of <span style='color: green;'>mount</span> <span style='color: green;'>f</span><span style='color: green;'>u</span><span style='color: green;'>ji</span>. my uncle told me, that many pilgrims travel to the ganges to purify themselves. there are also towns like lhasa and kathmandu that have such a unique vibe."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(37, 44), (154, 172), (268, 281)]\n",
      "1/1 [==============================] - 0s 101ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "The old map showed a path winding through the <span style='color: green;'>Cook</span>, leading to the shores of Lake Michigan. We decided to follow it, curious about the stories whispered by the wind around the peaks of <span style='color: green;'>Mount</span> <span style='color: green;'>Mitchell</span>. The journey took us through dense forests, where the sunlight barely touched the forest floor, and then opened onto the vast plains where the Missouri River snaked its way towards the Mississippi. The guide told us that beyond the next range, the <span style='color: green;'>O</span><span style='color: green;'>jos</span> <span style='color: green;'>del</span> <span style='color: green;'>Sal</span><span style='color: green;'>ado</span>, there was a legendary hidden valley, accessible only by crossing the treacherous <span style='color: green;'>Nan</span><span style='color: green;'>tai</span>. We hoped to reach it by the time the sun set behind <span style='color: green;'>Ta</span><span style='color: green;'>rum</span><span style='color: green;'>ae</span>, a distant beacon on our long trek. Along the way, we passed several small towns, their names like echoes of the past : Oak Haven, Riverbend, and Willow Creek. The sheer scale of the landscape, from the <span style='color: green;'>Andes</span> in our early dreams to the <span style='color: green;'>Alps</span>, which we ’ ve heard so much about from old travelers, dwarfed our expectations. This journey was more than just a trek, it was an immersion into the heart of the earth itself."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(37, 41), (151, 164), (372, 389), (463, 471), (512, 523), (695, 700), (721, 725)]\n",
      "1/1 [==============================] - 0s 92ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "The cultures nestled within the shadows of majestic mountain ranges often exhibit unique characteristics shaped by their environment. For instance, communities living near the <span style='color: green;'>Andes</span> mountains in South America have developed intricate terraced farming techniques to cultivate crops on the steep slopes. The <span style='color: green;'>Alps</span>, another formidable mountain range, have fostered a culture of mountaineering and winter sports, attracting enthusiasts from around the globe. Similarly, the Sherpa people, renowned for their climbing prowess, have a deep connection to the <span style='color: green;'>Him</span><span style='color: green;'>alaya</span><span style='color: green;'>s</span> and their sacred peaks, including the famous <span style='color: green;'>Robson</span> <span style='color: red;'>and</span> <span style='color: green;'>Gas</span><span style='color: green;'>san</span>. The Yangtze River, a vital waterway, flows through many areas influencing local cultures with its role in trade and transportation. Lake Baikal, a deep freshwater lake, is another example of how the water resources shape the traditions and livelihoods of local populations. These examples showcase that the natural landscapes around the <span style='color: green;'>Rocky</span> <span style='color: green;'>Mountains</span> or the <span style='color: green;'>Appalachian</span><span style='color: green;'>s</span>, for example, play an essential role in forming customs and rituals of people residing in these regions. The surrounding forests and rivers like the Rhine further add to the richness of cultural expressions. The cultural adaptations seen in these populations are a testament to the enduring relationship between humans and the imposing presence of mountains and their surrounding landscapes."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(156, 161), (271, 275), (493, 506), (544, 561), (866, 880), (885, 899)]\n",
      "1/1 [==============================] - 0s 94ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "The crisp air of the <span style='color: green;'>Andes</span> mountains always carries a hint of ancient stories. Villages nestled high in their valleys, like Cusco, hum with traditions passed down through generations. Life here revolves around the rhythm of the mountains, with the sun rising over <span style='color: green;'>Baker</span> each morning, painting the peaks in hues of orange and gold. The people are deeply connected to the land, their livelihoods often depending on the resources provided by the rugged terrain. The Amazon River begins its long journey not far from these heights, a lifeline flowing eastward toward the vast plains. The <span style='color: green;'>Rockies</span> in North America also hold similar stories. Communities there, like those near Lake Louise, have carved their own unique paths, adapting to the harsh winters and stunning beauty. The mythology of these people is replete with tales of spirits residing in the mountains, such as <span style='color: green;'>Ki</span><span style='color: green;'>na</span><span style='color: green;'>bal</span><span style='color: green;'>u</span>, treated with a mixture of reverence and awe. From the <span style='color: green;'>Yo</span><span style='color: green;'>te</span><span style='color: green;'>i</span> in Europe, with its picturesque villages dotting the landscape, to the <span style='color: green;'>Atlas</span> <span style='color: green;'>Mountains</span> in North Africa, each range holds a distinct culture that reflects the spirit of their towering homes. Rivers like the Rhine and the Rhône wind their way through these ranges, playing a crucial role in agriculture and transportation. The cultural impact of mountains is undeniable, shaping beliefs, traditions, and the very soul of the peoples who live in their shadows."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(16, 21), (227, 232), (502, 509), (747, 761), (810, 819), (881, 895)]\n",
      "1/1 [==============================] - 0s 98ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Exploring Yellowstone National Park offers an unforgettable experience. The park is home to the <span style='color: green;'>Rocky</span> <span style='color: green;'>Mountains</span>, with peaks visible throughout. The Yellowstone River flows through the park, creating stunning landscapes. Nearby is the city of Bozeman, a gateway to many adventures. The <span style='color: green;'>Gas</span><span style='color: green;'>san</span> range is also close, providing breathtaking views. Lake Yellowstone ’ s vastness is impressive, and the surrounding forests are full of wildlife. Many hiking trails wind their way through the foothills of the <span style='color: green;'>Townsend</span>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(98, 112), (265, 273), (455, 463)]\n",
      "1/1 [==============================] - 0s 94ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "The climb up <span style='color: green;'>Mount</span> <span style='color: green;'>Fuji</span> was challenging but rewarding. Many hikers visit <span style='color: green;'>Ta</span><span style='color: green;'>rum</span><span style='color: green;'>ae</span> every year. The <span style='color: green;'>Andes</span> mountain range is vast and beautiful. The Amazon River flows through the rainforest. <span style='color: green;'>R</span><span style='color: green;'>ora</span><span style='color: green;'>ima</span> is a popular destination for climbers. Lake Superior is one of the largest lakes in North America. The city of London is a major metropolis. The <span style='color: green;'>Saint</span> <span style='color: green;'>Helens</span> extend across several states."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(10, 19), (65, 76), (89, 94), (166, 177), (300, 311)]\n",
      "1/1 [==============================] - 0s 93ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "welcome back to the show, everyone. today, we' re discussing mountain regions, specifically focusing on some of the iconic peaks and the areas that surround them. we' ll start with <span style='color: green;'>mount</span> <span style='color: green;'>f</span><span style='color: green;'>u</span><span style='color: green;'>ji</span>, a majestic volcano located near tokyo in japan. moving westward, we have the massive <span style='color: green;'>al</span><span style='color: green;'>ps</span> range that stretches through several countries including france, switzerland and italy. these mountains are crossed by many rivers. the rhine river flows from those mountains. furthermore, we can talk about the <span style='color: green;'>and</span><span style='color: green;'>es</span>, a mountain chain in south america. cities like la paz are nestled within their range. lastly, <span style='color: green;'>mount</span> <span style='color: green;'>k</span><span style='color: green;'>ili</span><span style='color: green;'>man</span><span style='color: green;'>jar</span><span style='color: green;'>o</span> stands tall in tanzania, surrounded by savannahs."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(151, 164), (248, 254), (446, 453), (540, 564)]\n"
     ]
    }
   ],
   "source": [
    "print('Green if correct, red if incorect true, yellow if incorect false')\n",
    "for i in range(10):\n",
    "    sample = next(ds)\n",
    "    evaluate(model, tokenizer, sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1d2880-1965-4090-b533-60c7d95bab3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
